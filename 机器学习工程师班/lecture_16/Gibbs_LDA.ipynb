{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 词库里面有5个单词V：`money`, `loan`,`bank`,`river`,`stream`\n",
    "* 两个话题: `T1`, `T2`\n",
    "* 概率分布\n",
    " - θ1money=1/3, θ1loan=1/3, θ1bank=1/3\n",
    " - θ2bank=1/3, θ2stream=1/3, θ2river=1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['money', 'loan', 'bank', 'river', 'stream']\n",
    "z_1 = np.array([1/3, 1/3, 1/3, 0, 0])\n",
    "z_2 = np.array([0, 0,1/3, 1/3, 1/3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把两个topic分布转成phi矩阵（概率分布矩阵）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.        ],\n",
       "       [0.33333333, 0.        ],\n",
       "       [0.33333333, 0.33333333],\n",
       "       [0.        , 0.33333333],\n",
       "       [0.        , 0.33333333]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([z_1, z_2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.        ],\n",
       "       [0.33333333, 0.        ],\n",
       "       [0.33333333, 0.33333333],\n",
       "       [0.        , 0.33333333],\n",
       "       [0.        , 0.33333333]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_actual = np.array([z_1, z_2]).T.reshape(len(z_2), 2)\n",
    "phi_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream bank river bank river bank stream stream river\n",
      "bank loan loan loan bank bank loan bank bank money money bank money loan loan bank\n",
      "river bank bank river stream river river bank stream river river stream river river\n",
      "bank money loan loan bank bank money\n",
      "stream bank bank stream bank stream\n",
      "stream river bank river bank bank river stream bank river\n",
      "loan money money loan bank loan money money bank money bank loan\n",
      "money bank money loan money bank\n",
      "river river river stream river\n",
      "river river bank stream river\n",
      "bank money loan money bank loan loan money bank bank bank bank money\n",
      "loan money loan bank loan money bank money loan loan bank\n",
      "bank stream bank bank river river stream river bank river river stream stream river bank\n",
      "river bank river bank bank bank stream river bank\n",
      "money bank loan bank loan money\n",
      "bank loan money bank loan loan bank bank loan\n"
     ]
    }
   ],
   "source": [
    "# 生成16个文档\n",
    "D =16\n",
    "# 给出每个文档平均单词个数\n",
    "mean_length = 10\n",
    "# 根据泊松分布\n",
    "# 平均数为10，大小为16个的数组\n",
    "# array([10, 11,  9,  9, 18, 13,  4, 10, 10,  8, 10, 11, 16,  9, 12, 12])\n",
    "len_doc = np.random.poisson(mean_length, size=D)\n",
    "# 话题数\n",
    "T = 2\n",
    "# 从概率分布抽取单词，组成句子\n",
    "docs = []\n",
    "orig_topics = []\n",
    "for i in range(D):\n",
    "    z = np.random.randint(0, 2)\n",
    "    if z == 0:\n",
    "        # 是从a 中以概率P，随机选择3个, p没有指定的时候相当于是一致的分布\n",
    "        words = np.random.choice(vocab, size=(len_doc[i]), p=z_1).tolist()\n",
    "    else:\n",
    "        words = np.random.choice(vocab, size=(len_doc[i]), p=z_2).tolist()\n",
    "    orig_topics.append(z)\n",
    "    docs.append(words)\n",
    "\n",
    "# 打印生成的文本    \n",
    "for doc in docs:\n",
    "    print(\" \".join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个句子服从那个topic\n",
    "orig_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化指针"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单词的位置\n",
    "w_i = []\n",
    "# 执行顺序\n",
    "i = []\n",
    "# 文章的位置\n",
    "d_i = []\n",
    "# 随机初始化topic分布\n",
    "z_i = []\n",
    "counter = 0\n",
    "for doc_idx, doc in enumerate(docs):\n",
    "    for words_idx, word in enumerate(doc):\n",
    "        # 找到目前这个单词在V中的位置\n",
    "        w_i.append(np.where(np.array(vocab) == word)[0][0])\n",
    "        # 记录i\n",
    "        i.append(counter)\n",
    "        # 记录文章的位置\n",
    "        d_i.append(doc_idx)\n",
    "        # 随机初始化topic分布\n",
    "        z_i.append(np.random.randint(0,T))\n",
    "        counter +=1\n",
    "w_i = np.array(w_i)\n",
    "d_i = np.array(d_i)\n",
    "z_i = np.array(z_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT = np.zeros((len(vocab), T))\n",
    "for idx, word_ in enumerate(vocab):\n",
    "    topics = z_i[np.where(w_i == idx)]\n",
    "    for t in range(T):\n",
    "        WT[idx, t] = sum(topics==t)\n",
    "\n",
    "DT = np.zeros((D,T))\n",
    "for idx, doc in enumerate(range(D)):\n",
    "    topics = z_i[np.where(d_i == idx)]\n",
    "    for t in range(T):\n",
    "        DT[idx, t] = sum(topics==t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_orig = WT.copy()\n",
    "DT_orig = DT.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10., 13.],\n",
       "       [11., 16.],\n",
       "       [26., 28.],\n",
       "       [20., 11.],\n",
       "       [10.,  8.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一个单词在第一个top出现了10次，在第二个top出现了13次\n",
    "WT_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 4.],\n",
       "       [7., 9.],\n",
       "       [9., 5.],\n",
       "       [5., 2.],\n",
       "       [3., 3.],\n",
       "       [6., 4.],\n",
       "       [6., 6.],\n",
       "       [2., 4.],\n",
       "       [4., 1.],\n",
       "       [2., 3.],\n",
       "       [8., 5.],\n",
       "       [4., 7.],\n",
       "       [8., 7.],\n",
       "       [4., 5.],\n",
       "       [1., 5.],\n",
       "       [3., 6.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在第一个top下出现了5，在第二个top出现了4次，类似\n",
    "DT_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs 取样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这就是我们刚刚讲的采样记录仪。记录下每一个phi的变化结果。\n",
    "phi_1 = np.zeros((len(vocab),100))\n",
    "phi_2 = np.zeros((len(vocab),100))\n",
    "\n",
    "# 总共跑100次\n",
    "iters = 100\n",
    "\n",
    "# 安排一个Dirichlet先验分布（通过参数）\n",
    "# 也就是课上说的 a, b 两个参数\n",
    "beta = 1.\n",
    "alpha = 1.\n",
    "\n",
    "for step in range(iters):\n",
    "    for current in i:\n",
    "        # 把D和W分别拿出来\n",
    "        doc_idx = d_i[current] \n",
    "        w_idx = w_i[current]\n",
    "                \n",
    "        # 并把这两个从总体集合中减去\n",
    "        DT[doc_idx,z_i[current]] -= 1\n",
    "        WT[w_idx,z_i[current]] -= 1\n",
    "        \n",
    "        # 计算新的W和D的分布\n",
    "        prob_word =  (WT[w_idx,:] + beta) / (WT[:,:].sum(axis=0) + len(vocab)* beta)\n",
    "        prob_document = (DT[doc_idx,:] + alpha) / (DT.sum(axis=0) + D*alpha)\n",
    "        # 这其实就是对于每个topic的概率\n",
    "        prob = prob_word * prob_document\n",
    "        \n",
    "        # 把Z更新（根据刚刚求得的prob）\n",
    "        z_i[current] = np.random.choice([0,1], 1, p=prob/prob.sum())[0]\n",
    "\n",
    "        # 更新计数器\n",
    "        DT[doc_idx,z_i[current]] += 1\n",
    "        WT[w_idx,z_i[current]] += 1\n",
    "        \n",
    "        # 记录下Phi的变化\n",
    "        phi  = WT/(WT.sum(axis=0))\n",
    "        phi_1[:,step] = phi[:,0]\n",
    "        phi_2[:,step] = phi[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.,  0.],\n",
       "       [11.,  0.],\n",
       "       [ 8.,  1.],\n",
       "       [ 1.,  8.],\n",
       "       [ 0., 18.],\n",
       "       [ 0., 13.],\n",
       "       [ 0.,  4.],\n",
       "       [10.,  0.],\n",
       "       [ 3.,  7.],\n",
       "       [ 1.,  7.],\n",
       "       [ 2.,  8.],\n",
       "       [ 0., 11.],\n",
       "       [ 1., 15.],\n",
       "       [ 9.,  0.],\n",
       "       [12.,  0.],\n",
       "       [12.,  0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.,  0.],\n",
       "       [27.,  0.],\n",
       "       [28., 29.],\n",
       "       [ 0., 28.],\n",
       "       [ 0., 35.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3125    , 0.        ],\n",
       "       [0.3375    , 0.        ],\n",
       "       [0.35      , 0.31521739],\n",
       "       [0.        , 0.30434783],\n",
       "       [0.        , 0.38043478]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi  = WT/(WT.sum(axis=0))\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90196078, 0.09803922],\n",
       "       [0.12568306, 0.87431694],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.33014354, 0.66985646],\n",
       "       [0.14110429, 0.85889571],\n",
       "       [0.22330097, 0.77669903],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07120743, 0.92879257],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计\n",
    "theta = DT/DT.sum(axis=0)\n",
    "# 归一\n",
    "theta = theta/np.sum(theta, axis=1).reshape(16,1) \n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(theta, axis=1) == orig_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
